## Cosine Similarity
I try to implement a variant of cosine similarity (with the L1-
Norm) as the ranking function. This essentially involves constructing the
document vector and the query vector and then taking their dot product.

###Document vector
####Term frequency
I compute the raw term frequencies for each query term in the different fields using the method For each of the
fields, we can compute the tf vector, either using the raw scores themselves or by applying sublinear scaling on the raw scores (In sublinear
scaling, we have tfi = 1 + log(rsi) if rsi > 0 and 0 otherwise. Thus,
the tf vector for the body field for qd will be

1:6931 0 0 2:6094

####Document frequency
We will not use any document frequency in the document vector. In-
stead, it is incorporated in the query vector as described below.
####Normalization
We cannot use cosine normalization as we do not have access to the
contents of the document and, thus, do not know what other terms
(and counts of those terms) occur in the body eld. As a result, we
use length normalization instead. Moreover, since there can be huge
discrepancies between the lengths of the dierent elds, we divide all
elds by the same normalization factor, the body length (Note that
some documents have a body length of 0, so you will have to smooth
them somehow. A good strategy is to add a value, say 500, to the
body length of each document. You can experiment with this value or
with other smoothing strategies and report them).

Query vector
 Term frequency
The raw term frequencies can be computed using the query (should be
1 for most queries but not necessarily true). Again, you can use either
the raw frequencies or sublinearly scale them. 
 Document frequency
Each of the terms in qv should be weighted using the idf value for
each of the terms in the query. Computing the idf requires going to
the corpus from PA1 to determine how many documents contain the
query terms. One issue is that it is possible for a query term t to not
appear in the collection corpus and it is not possible to evaluate idft.
In such a case, we will apply the Laplace add-one smoothing technique
learned earlier in the course (This essentially assumes the existence of
a hypothetical dummy document that contains all possible terms, and
therefore, adds 1 to each numerator and denominator with the idft
formula).
 Normalization
No normalization is needed for query length because any query length
normalization applies to all docs and so is not relevant to ranking.
For a document d and query q, if qvq is the query vector and tfd;u, tfd;t,
tfd;b, tfd;h and tfd;a are the term score vector for the url, title, body, header
and anchor elds, respectively, then the net score is qvq  (cu tfd;u+ct tfd;t+
cb  tfd;b + ch  tfd;h + ca  tfd;a). Here, cu, ct, cb, ch and ca are the weights
given to url, title, body, header and anchors elds, respectively.
The goal is to determine the weights for all 5 elds (and, thus, the ranking
function using cosine similarity) so that the NDCG function is of a optimal
value when run on the test set. You will use the training set given to derive
the above parameters. In the report, you should mention parameter
values and describe brie
y the intuition and reasons behind why
the weights were selected.
Hint: Note that the absolute values of weights won't matter as they will
be the same for all documents, only the relative weights for dierent elds is
important; i.e. you can multiply each weight by a constant and the ranking
will remain the same. In order to estimate the relative weights, try to reason
the relative importance of the dierent elds.
